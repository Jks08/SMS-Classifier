{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jishnu_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets #comment it if you already have it installed\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "source": [
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "source": [
        "df_train = pd.read_csv(train_file_path,sep=\"\\t\",header=None)\n",
        "df_test = pd.read_csv(test_file_path,sep=\"\\t\",header=None)\n",
        "df_train[0]=df_train[0].replace(\"ham\",0) \n",
        "df_train[0]=df_train[0].replace(\"spam\",1)\n",
        "df_test[0]=df_test[0].replace(\"ham\",0)\n",
        "df_test[0]=df_test[0].replace(\"spam\",1)\n",
        "df_train[0]=df_train[0].astype('int64')\n",
        "df_test[0]=df_test[0].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((df_train[1],df_train[0]))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((df_test[1],df_test[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6s-PKbV93Qs"
      },
      "source": [
        "tokenizer=tfds.deprecated.text.Tokenizer()\n",
        "vocabulary_set = set()\n",
        "for text_tensor, _ in train_dataset.concatenate(test_dataset):\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
        "  vocabulary_set.update(some_tokens)\n",
        "vocab_size = len(vocabulary_set)\n",
        "encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyFVgxOp_Ony"
      },
      "source": [
        "def encode(text_tensor,label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label\n",
        "\n",
        "def encoded_map_fn(text,label):\n",
        "  encoded_text, label = tf.py_function(encode,inp=[text,label],Tout=(tf.int64, tf.int64))\n",
        "  encoded_text.set_shape([None])\n",
        "  label.set_shape([])\n",
        "  return encoded_text,label\n",
        "train_dataset_encoded = train_dataset.map(encoded_map_fn)\n",
        "test_dataset_encoded = test_dataset.map(encoded_map_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJAtyE-4ANum"
      },
      "source": [
        "for train_example, train_label in train_dataset_encoded.take(2):\n",
        "  print(f\"Encoded Text: {train_example[:10].numpy()}\")\n",
        "  print(f\"Label: {train_label.numpy()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnZLnEyRAnLI"
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "train_batches = (train_dataset_encoded.shuffle(BUFFER_SIZE).padded_batch(32))\n",
        "test_batches = (test_dataset_encoded.padded_batch(32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRDN_eNSAnJo"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                          keras.layers.Embedding(encoder.vocab_size,16),\n",
        "                          keras.layers.GlobalAveragePooling1D(),\n",
        "                          keras.layers.Dense(1, activation=\"sigmoid\")])\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tf_kvfGGHRK"
      },
      "source": [
        "history = model.fit(train_batches, epochs=10,validation_data=test_batches,validation_steps=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "source": [
        "def predict_message(pred_text):\n",
        "  encoded_pred_text=encoder.encode(pred_text)\n",
        "  encoded_pred_text=tf.cast(encoded_pred_text,tf.float32)\n",
        "  prediction = model.predict(tf.expand_dims(encoded_pred_text,tf.constant(0))).tolist()\n",
        "  prediction=prediction[0]\n",
        "  if prediction[0]<0.5:\n",
        "    prediction.append(\"ham\")\n",
        "  else:\n",
        "    prediction.append(\"spam\")\n",
        "  return (prediction) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T66nhqJyFjQE"
      },
      "source": [
        "print(f\"Model Accuracy: {prediction[0]*100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riRUTg7-FvHj"
      },
      "source": [
        "pred_text = input(\"Enter SMS: \")\n",
        "prediction = predict_message(pred_text)\n",
        "print(\"Ham means genuine message, Spam means Scam!\")\n",
        "print(f\"SMS is: {prediction[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}